# app_intent_driven.py
from __future__ import annotations
import os, re, json, traceback
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime, date, timedelta

import streamlit as st
import pandas as pd
import google.generativeai as genai

# .env ë¡œë”©
try:
    from dotenv import load_dotenv, find_dotenv
    p = find_dotenv(usecwd=True)
    if p: load_dotenv(p, override=False)
except Exception: pass

# API í‚¤ ì„¤ì •
DART_API_KEY = os.getenv("DART_API_KEY") or ""
NAVER_ID = os.getenv("NAVER_CLIENT_ID") or ""
NAVER_SECRET = os.getenv("NAVER_CLIENT_SECRET") or ""
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY") or ""
if GOOGLE_API_KEY: genai.configure(api_key=GOOGLE_API_KEY)

# ---- í”„ë¡œì íŠ¸ ë‚´ ìœ í‹¸ (ê¸°ì¡´ íŒŒì¼ í™œìš©) ----
from dart_functions import (
    get_dart_indicators_quarterly, normalize_financial_payload, add_growth_cols,
    apply_unit_format, get_ticker_from_name_fuzzy, BRAND_FIXES,
    get_historical_price, get_corp_outline
)
import navernews as newsmod
# --- Gemini ìë™ í•¨ìˆ˜ í˜¸ì¶œì„ ìœ„í•œ ë„êµ¬ ì„í¬íŠ¸ ---
import gemini_functions

st.set_page_config(page_title="K-ì£¼ì‹ AI ì±—ë´‡", page_icon="ğŸ“ˆ", layout="wide")
st.title("ğŸ“ˆ AI ì£¼ì‹ ë¶„ì„ ì±—ë´‡")

# --- 1. ì˜ë„ ë¶„ì„ ë¡œì§ (ë‹¨ìˆœ/ë³µí•© ì§ˆë¬¸ êµ¬ë¶„) ---
PRICE_WORDS = ["ì£¼ê°€", "ì‹œì„¸", "ì¢…ê°€", "ê°€ê²©", "ì–¼ë§ˆ"]
NEWS_WORDS = ["ë‰´ìŠ¤", "ê¸°ì‚¬", "ì†Œì‹", "ì´ìŠˆ", "ë¦¬í¬íŠ¸", "ê³µì‹œ"]
FIN_WORDS  = ["ì‹¤ì ", "ì¬ë¬´", "ë¶„ê¸°", "ì§€í‘œ", "ê°€ì¹˜", "eps", "roe", "ë§¤ì¶œ", "ì˜ì—…ì´ìµ", "per"]
OUTLINE_WORDS = ["ì„¤ëª…", "ê°œìš”", "ê¸°ì—…ì •ë³´", "ì–´ë–¤ íšŒì‚¬"]
FORECAST_WORDS = ["ì „ë§", "ì˜ˆì¸¡", "ì–´ë•Œ", "ì–´ë–¨ê¹Œ", "ì•ìœ¼ë¡œ", "íˆ¬ì"]
KNOWN_CORP_ALIASES = sorted(list(BRAND_FIXES.keys()), key=len, reverse=True)

def parse_relative_date(query: str) -> Optional[date]:
    if "ì˜¤ëŠ˜" in query: return date.today()
    if "ì–´ì œ" in query: return date.today() - timedelta(days=1)
    return None

def parse_query_simple(query: str) -> Tuple[str, str, Optional[date]]:
    """ë‹¨ìˆœí•˜ê³  ëª…í™•í•œ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤. ë³µì¡í•œ ì§ˆë¬¸ì€ 'complex_query'ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    lower_q = query.lower()
    
    # --- ì•ˆì •ì„±ì„ ë†’ì¸ ìƒˆë¡œìš´ ë‹¤ì¤‘ ê¸°ì—… ì¸ì‹ ë¡œì§ ---
    found_subjects = []
    # ì¤‘ë³µ ì¸ì‹ì„ ë°©ì§€í•˜ê¸° ìœ„í•´, ì°¾ì€ ê¸°ì—…ëª…ì„ ì„ì‹œë¡œ ë§ˆìŠ¤í‚¹
    temp_q = lower_q
    for alias in KNOWN_CORP_ALIASES:
        # ì •ê·œì‹ìœ¼ë¡œ ë‹¨ì–´ ê²½ê³„ë¥¼ í™•ì¸í•˜ì—¬ 'ì‚¼ì„±ì „ì'ê°€ 'ì‚¼ì„±ì „ê¸°'ë¥¼ í¬í•¨í•˜ì§€ ì•Šë„ë¡ í•¨
        # re.IGNORECASEë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë§¤ì¹­
        for match in re.finditer(r'\b' + re.escape(alias) + r'\b', temp_q, re.IGNORECASE):
            original_term = query[match.start():match.end()]
            found_subjects.append(original_term)
            # ì°¾ì€ ë¶€ë¶„ì€ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì¤‘ë³µ ê²€ìƒ‰ ë°©ì§€
            temp_q = temp_q[:match.start()] + "[MASKED]" * len(alias) + temp_q[match.end():]

    # ë‘ ê°œ ì´ìƒì˜ ê¸°ì—…ì´ ì–¸ê¸‰ë˜ë©´ ë¹„êµ ë“± ë³µí•© ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬
    if len(found_subjects) > 1:
        return query, "complex_query", None
        
    found_subject = found_subjects[0] if found_subjects else ""
    
    subject = found_subject if found_subject else query.strip()
    target_date = parse_relative_date(lower_q)
    
    if any(w in lower_q for w in FORECAST_WORDS):
        return query, "complex_query", None
    if any(w in lower_q for w in NEWS_WORDS):
        return subject, "news", None
    if any(w in lower_q for w in OUTLINE_WORDS):
        return subject, "outline", None
    if target_date or any(w in lower_q for w in PRICE_WORDS):
        return subject, "price_history", target_date or date.today()
    if any(w in lower_q for w in FIN_WORDS):
        return subject, "finance", None
    
    return query, "complex_query", None

# --- 2. ë‹µë³€ ìƒì„± í•¨ìˆ˜ë“¤ ---
def answer_complex_query(query: str) -> str:
    """Geminiì˜ ìë™ í•¨ìˆ˜ í˜¸ì¶œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ë³µí•©ì ì¸ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤."""
    if not GOOGLE_API_KEY: return "âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ í•  ìˆ˜ ì—†ì–´ìš”."
    st.info("AIê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , í•„ìš”í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¢…í•©ì ì¸ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")

    try:
        model = genai.GenerativeModel(
            model_name='gemini-2.5-flash',
            tools=gemini_functions.tools
        )
        chat = model.start_chat(enable_automatic_function_calling=True)
        response = chat.send_message(query)
        return response.text
    except Exception as e:
        return f"âŒ AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def answer_outline(subject: str) -> str:
    corp_info = get_ticker_from_name_fuzzy(subject)
    if not corp_info.get("best"): return f"âŒ '{subject}' ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    best_match = corp_info["best"]
    outline_data = get_corp_outline(best_match["corp_code"])
    if outline_data.get("status") != "000": return f"âŒ ê¸°ì—… ê°œí™© ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {outline_data.get('message')}"
    hm_url = outline_data.get('hm_url')
    hm_link = f"[{hm_url}]({hm_url})" if hm_url and hm_url.startswith('http') else "ì •ë³´ ì—†ìŒ"
    response_lines = [f"### ğŸ¢ {outline_data.get('corp_name', '')}", "---", f"- **ëŒ€í‘œì**: {outline_data.get('ceo_nm', 'ì •ë³´ ì—†ìŒ')}", f"- **ì„¤ë¦½ì¼**: {outline_data.get('est_dt', 'ì •ë³´ ì—†ìŒ')}", f"- **ì£¼ì†Œ**: {outline_data.get('adres', 'ì •ë³´ ì—†ìŒ')}", f"- **í™ˆí˜ì´ì§€**: {hm_link}", f"- **ì£¼ìš”ì‚¬ì—…**: {outline_data.get('main_bsns_nm', 'ì •ë³´ ì—†ìŒ')}"]
    return "\n".join(response_lines)

def answer_price_history(subject: str, target_date: date) -> str:
    corp_info = get_ticker_from_name_fuzzy(subject)
    if not corp_info.get("best"): return f"âŒ '{subject}' ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    best_match, corp_name, stock_code = corp_info["best"], corp_info["best"]["corp_name"], corp_info["best"]["stock_code"]
    if not stock_code or not stock_code.strip(): return f"âŒ '{corp_name}'ì€(ëŠ”) ìƒì¥ì‚¬ê°€ ì•„ë‹™ë‹ˆë‹¤."
    ticker = f"{stock_code}.KS"
    result = get_historical_price(ticker, target_date)
    if result.get("error"):
        ticker_kq = ticker.replace(".KS", ".KQ")
        result = get_historical_price(ticker_kq, target_date)
    if result.get("error"): return f"âŒ '{corp_name}' ì£¼ê°€ ì¡°íšŒ ì˜¤ë¥˜: {result['error']}"
    price_date, close_price = result['date'], result['close']
    return f"**{price_date}** ê¸°ì¤€ **{corp_name}**ì˜ ì¢…ê°€ëŠ” **{close_price:,.0f}ì›**ì…ë‹ˆë‹¤."

def answer_finance(subject: str, years: int = 2) -> Tuple[str, Optional[pd.DataFrame]]:
    corp_info = get_ticker_from_name_fuzzy(subject)
    if not corp_info.get("best"): return f"âŒ '{subject}' ê¸°ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
    payload = get_dart_indicators_quarterly(corp_name=corp_info["best"]["corp_name"], symbol=corp_info["best"]["stock_code"], years=years)
    if payload.get("error"): return f"âŒ ì¬ë¬´ ì¡°íšŒ ì‹¤íŒ¨: {payload.get('error')}", None
    meta, df_raw = normalize_financial_payload(payload)
    if df_raw.empty: return "ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.", None
    df_growth = add_growth_cols(df_raw)
    latest4 = df_growth.head(4).to_dict(orient="records")
    bullets = []
    for r in latest4:
        qlab = f"{int(r['ì—°ë„'])}ë…„ {r['ë¶„ê¸°']}" if pd.notna(r.get('ì—°ë„')) else "ìµœì‹  ë¶„ê¸°"
        s = [f"{lab} {val:,.2f}ì–µì›" for col, lab in [("ë§¤ì¶œ","ë§¤ì¶œ"), ("ì˜ì—…ì´ìµ","ì˜ì—…ì´ìµ")] if (val:=r.get(col)) is not None and pd.notna(val)]
        try: s += [f"{lab} {f_str.format(v=r[col])}" for col, lab, f_str in [("EPS","EPS","{v:,.0f}ì›"), ("PER","PER","{v:.2f}ë°°"), ("ROE(%)","ROE","{v:.2f}%")] if r.get(col) is not None and pd.notna(r.get(col))]
        except (ValueError, TypeError): pass
        bullets.append(f"- **{qlab}**: " + (", ".join(s) if s else "(ìˆ˜ì¹˜ ì—†ìŒ)"))
    header = f"**{meta.corp_name}** (ì½”ë“œ: {meta.stock_code}) Â· {years}ë…„"
    return header + "\n\n" + "\n".join(bullets), apply_unit_format(df_growth)

def answer_news(subject: str, limit: int = 8) -> Tuple[str, List[Dict[str, Any]]]:
    payload = newsmod.search_latest_news_naver(query=subject, display=max(30, limit), sort="date", recent_days=30, return_meta=True)
    if payload.get("error"): return f"âŒ ë‰´ìŠ¤ API ì˜¤ë¥˜: {payload.get('error')}", []
    items = payload.get("items", [])
    if not items: return f"'{subject}' ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.", []
    summarized = newsmod.summarize_news_and_sentiment_naver({"items": items})
    with_topics = newsmod.classify_news_topics_naver(summarized)
    shown = with_topics.get("items", [])[:limit]
    title = f"ğŸ“° **ë‰´ìŠ¤ ìš”ì•½ â€” '{subject}'** (ê²°ê³¼: {len(shown)}ê±´)"
    return title, shown

# --------- 3. ë©”ì¸ UI ë¡œì§ ---------
if "chat" not in st.session_state:
    st.session_state.chat: List[Dict[str, Any]] = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! AI ì£¼ì‹ ë¶„ì„ ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"}]

for msg in st.session_state.chat:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"], unsafe_allow_html=True)
        if isinstance(msg.get("df"), pd.DataFrame) and not msg.get("df").empty:
            with st.expander("ìƒì„¸ í‘œ ë³´ê¸°"): st.dataframe(msg["df"], use_container_width=True, hide_index=True)
        if msg.get("news"):
            with st.expander("ë‰´ìŠ¤ ëª©ë¡ ë³´ê¸°"):
                for it in msg["news"]:
                    link, date_str = it.get("originallink") or it.get("link") or "#", it.get("pubDateKST", "")
                    try: date_iso = pd.to_datetime(date_str).strftime('%Y-%m-%d %H:%M') if date_str else it.get("pubDate", "")
                    except pd.errors.ParserError: date_iso = it.get("pubDate", "")
                    st.markdown(f"- [{it.get('title','(ì œëª© ì—†ìŒ)')}]({link}) ({date_iso})")

user_q = st.chat_input("ì˜ˆ: 'ì‚¼ì„±ì „ì ì‹¤ì ', 'ì¹´ì¹´ì˜¤ ì–´ì œ ì£¼ê°€', 'HBM ê´€ë ¨ ë‰´ìŠ¤ 10ê°œ', 'í˜„ëŒ€ì°¨ì™€ ê¸°ì•„ì°¨ ì‹¤ì  ë¹„êµ'")
if user_q:
    st.session_state.chat.append({"role": "user", "content": user_q})
    
    subject, intent, target_date = parse_query_simple(user_q)
    
    with st.chat_message("assistant"):
        with st.spinner(f"'{subject}'({intent}) ë¶„ì„ ì¤‘... ğŸš€"):
            try:
                if intent == "complex_query":
                    response_text = answer_complex_query(user_q)
                    st.session_state.chat.append({"role": "assistant", "content": response_text})
                elif intent == "outline":
                    response_text = answer_outline(subject)
                    st.session_state.chat.append({"role": "assistant", "content": response_text})
                elif intent == "price_history" and target_date:
                    response_text = answer_price_history(subject, target_date)
                    st.session_state.chat.append({"role": "assistant", "content": response_text})
                elif intent == "news":
                    limit = int(re.search(r'(\d+)\s*ê°œ', user_q).group(1)) if re.search(r'(\d+)\s*ê°œ', user_q) else 5
                    response_text, items = answer_news(user_q, limit=limit)
                    st.session_state.chat.append({"role": "assistant", "content": response_text, "news": items})
                else: # finance
                    years = int(re.search(r"(\d+) ?ë…„", user_q).group(1)) if re.search(r"(\d+) ?ë…„", user_q) else 2
                    body, df_show = answer_finance(subject, years=years)
                    st.session_state.chat.append({"role": "assistant", "content": body, "df": df_show})
            except Exception:
                error_msg = f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n```\n{traceback.format_exc()}\n```"
                st.session_state.chat.append({"role": "assistant", "content": error_msg})
    st.rerun()