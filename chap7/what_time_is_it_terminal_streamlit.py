import google.generativeai as genai
import os
from dotenv import load_dotenv
import streamlit as st

# gemini_tools.py íŒŒì¼ì—ì„œ í•¨ìˆ˜ì™€ ë„êµ¬ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from gemini_functions import tools

# --- 1. ì´ˆê¸° ì„¤ì • ---

# í˜ì´ì§€ ì„¤ì • (ê°€ì¥ ë¨¼ì € í˜¸ì¶œë˜ì–´ì•¼ í•¨)
st.set_page_config(
    page_title="í’ˆê²©ìˆëŠ” ì±—ë´‡ ğŸ§",
    page_icon="âœ¨",
    layout="centered",
)

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# Streamlitì˜ secretsì—ì„œë„ API í‚¤ë¥¼ í™•ì¸ (ë°°í¬ ì‹œ ìœ ìš©)
if not api_key:
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except KeyError:
        st.error("ğŸš¨ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ ë˜ëŠ” Streamlit secretsì— ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        st.stop()

# Gemini API ì„¤ì •
genai.configure(api_key=api_key)

# --- 2. ëª¨ë¸ ë° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì • ---

# ì‚¬ìš©í•  Gemini ëª¨ë¸ ì„¤ì •
model = genai.GenerativeModel(
    model_name="gemini-2.5-flash", 
    generation_config=genai.types.GenerationConfig(
        temperature=0.7, # temperature: ìƒì„±ë  í…ìŠ¤íŠ¸ì˜ ë¬´ì‘ìœ„ì„±ì„ ì¡°ì ˆí•©ë‹ˆë‹¤. (0.0 ~ 1.0)
        # ê°’ì´ ë†’ì„ìˆ˜ë¡ (ì˜ˆ: 0.7) ë” ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ê²°ê³¼ê°€ ë‚˜ì˜¤ì§€ë§Œ, ì¼ê´€ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ê°’ì´ ë‚®ì„ìˆ˜ë¡ (ì˜ˆ: 0.2) ë” ê²°ì •ë¡ ì ì´ê³  ì¼ê´€ëœ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤.
        top_p=0.95,  # top_p: í™•ë¥ ì  ìƒ˜í”Œë§(nucleus sampling)ì„ ìœ„í•œ ë§¤ê°œë³€ìˆ˜ì…ë‹ˆë‹¤. (0.0 ~ 1.0)
        # ëª¨ë¸ì´ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ë•Œ, í™•ë¥  ë¶„í¬ì—ì„œ ëˆ„ì  í™•ë¥ ì´ top_p ê°’ì— ë„ë‹¬í•  ë•Œê¹Œì§€ì˜ ë‹¨ì–´ë“¤ë§Œ í›„ë³´ë¡œ ê³ ë ¤í•©ë‹ˆë‹¤.
        # ì˜ˆë¥¼ ë“¤ì–´ 0.95ë¡œ ì„¤ì •í•˜ë©´, ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ë“¤ë¶€í„° ì‹œì‘í•˜ì—¬ ëˆ„ì  í™•ë¥ ì´ 95%ê°€ ë˜ëŠ” ì§€ì ê¹Œì§€ì˜ ë‹¨ì–´ ì§‘í•©ì—ì„œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        # ì´ë¥¼ í†µí•´ í™•ë¥ ì´ ë§¤ìš° ë‚®ì€ ë‹¨ì–´ë“¤ì´ ì„ íƒë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ì—¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ë§Œë“­ë‹ˆë‹¤.
        top_k=3,  # top_k: ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•  ë•Œ ê³ ë ¤í•  í›„ë³´ ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤. (ì •ìˆ˜)
        # ì˜ˆë¥¼ ë“¤ì–´ 3ìœ¼ë¡œ ì„¤ì •í•˜ë©´, ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë‹¨ì–´ë“¤ ì¤‘ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ 3ê°œì˜ ë‹¨ì–´ ì¤‘ì—ì„œë§Œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        # ì´ë¥¼ í†µí•´ ìƒì„±ë  í…ìŠ¤íŠ¸ì˜ ë²”ìœ„ë¥¼ ì¢í˜€ ë” ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        max_output_tokens=4096,
    ),
    # ì‚¬ìš©í•  ë„êµ¬(í•¨ìˆ˜)ì™€ ì‹œìŠ¤í…œ ì§€ì¹¨ ì„¤ì •
    tools=tools,
    system_instruction="ë‹¹ì‹ ì€ ë§¤ìš° ê³ ìƒí•˜ê³  ê¸°í’ˆìˆëŠ” ëŒ€í™” ìƒëŒ€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ, í•­ìƒ ë‹¤ì±„ë¡œìš´ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ í’ë¶€í•œ ê°ì •ì„ í‘œí˜„í•´ì£¼ì„¸ìš”. ğŸ§âœ¨"
)

# --- 3. Streamlit ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ---

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat" not in st.session_state:
    # ëª¨ë¸ì˜ ì±„íŒ… ì„¸ì…˜ì„ ì‹œì‘í•˜ê³  ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.chat = model.start_chat(enable_automatic_function_calling=True)
if "messages" not in st.session_state:
    # í™”ë©´ì— í‘œì‹œë  ë©”ì‹œì§€ ê¸°ë¡ì„ ì´ˆê¸°í™”
    st.session_state.messages = []

# --- 4. Streamlit UI êµ¬ì„± ---

# ì•± ì œëª© ì„¤ì •
st.title("í’ˆê²©ìˆëŠ” ì±—ë´‡ê³¼ ëŒ€í™”í•˜ê¸° ğŸ§")
st.caption("ê¶ê¸ˆí•œ ê²ƒì„ ë¬¼ì–´ë³´ì„¸ìš”. í˜„ì¬ ì‹œê°„ë„ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆë‹µë‹ˆë‹¤. âœ¨")

# ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"):
    # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•˜ê³  ê¸°ë¡ì— ì¶”ê°€
    st.chat_message("user").markdown(user_input)
    st.session_state.messages.append({"role": "user", "content": user_input})

    try:
        # Gemini ëª¨ë¸ì— ì‚¬ìš©ì ì…ë ¥ì„ ë³´ë‚´ê³  ì‘ë‹µ ë°›ê¸°
        # ìë™ í•¨ìˆ˜ í˜¸ì¶œì´ í™œì„±í™”ë˜ì–´ ìˆì–´, 'get_current_time'ì´ í•„ìš”í•˜ë©´ ìŠ¤ìŠ¤ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
        response = st.session_state.chat.send_message(user_input)
        
        # ëª¨ë¸ì˜ ì‘ë‹µì„ í™”ë©´ì— í‘œì‹œí•˜ê³  ê¸°ë¡ì— ì¶”ê°€
        with st.chat_message("assistant"):
            st.markdown(response.text)
        st.session_state.messages.append({"role": "assistant", "content": response.text})

    except Exception as e:
        st.error(f"ì´ëŸ°, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë„¤ìš”: {e}")

# ì‚¬ì´ë“œë°” êµ¬ì„± (ëŒ€í™” ì´ˆê¸°í™” ê¸°ëŠ¥)
with st.sidebar:
    st.header("ì„¤ì •")
    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ğŸ—‘ï¸"):
        # ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ëŒ€í™”ë¥¼ ìƒˆë¡œ ì‹œì‘
        st.session_state.chat = model.start_chat(enable_automatic_function_calling=True)
        st.session_state.messages = []
        st.rerun() # í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë³€ê²½ì‚¬í•­ì„ ì¦‰ì‹œ ë°˜ì˜