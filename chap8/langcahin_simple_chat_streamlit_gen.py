import streamlit as st
import os
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from datetime import datetime
import pytz

# --- API í‚¤ ì„¤ì • ---
load_dotenv()
google_api_key = os.getenv("GOOGLE_API_KEY")
if not google_api_key:
    st.error("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()
# --------------------

# 1. ëª¨ë¸ ì´ˆê¸°í™” (ìš”ì²­í•˜ì‹  gemini-2.5-flash ì‚¬ìš©)
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=google_api_key)

# 2. ë„êµ¬ í•¨ìˆ˜ ì •ì˜ (ì›ë³¸ê³¼ ë™ì¼)
@tool
def get_current_time(timezone: str, location: str) -> str:
    """í˜„ì¬ ì‹œê°ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜."""
    try:
        tz = pytz.timezone(timezone)
        now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        result = f'{timezone} ({location}) í˜„ì¬ì‹œê° {now}'
        print(result)
        return result
    except pytz.UnknownTimeZoneError:
        return f"ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì„ì¡´: {timezone}"

# 3. ë„êµ¬ ë°”ì¸ë”© (ì›ë³¸ê³¼ ë™ì¼)
tools = [get_current_time]
tool_dict = {"get_current_time": get_current_time}
llm_with_tools = llm.bind_tools(tools)


# 4. (ì‹ ê·œ) ìŠ¤íŠ¸ë¦¬ë° ë° ë©”ì‹œì§€ ì¡°ë¦½ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def stream_and_assemble_response(messages):
    """
    LLM ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ê³ , ì „ì²´ ì²­í¬(chunk)ë¥¼ ì¡°ë¦½í•˜ì—¬
    (ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„°, ì¡°ë¦½ëœ ë©”ì‹œì§€)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    stream = llm_with_tools.stream(messages)
    
    # ì²­í¬ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    stream_chunks = []
    
    # UI ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì œë„ˆë ˆì´í„°
    def generator_for_ui():
        for chunk in stream:
            stream_chunks.append(chunk) # ì²­í¬ ì €ì¥
            if chunk.content:
                yield chunk.content # UIì—ëŠ” ë¬¸ìì—´ contentë§Œ ì „ë‹¬
    
    # ì¡°ë¦½ëœ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
    def get_assembled_message():
        if not stream_chunks:
            return AIMessage(content="") # ë¹ˆ ì‘ë‹µ ì²˜ë¦¬
            
        # ëª¨ë“  ì²­í¬ë¥¼ ë”í•˜ì—¬ ì™„ì „í•œ AIMessage ê°ì²´ë¡œ ë§Œë“¦
        assembled_message = stream_chunks[0]
        for chunk in stream_chunks[1:]:
            assembled_message += chunk
        return assembled_message

    return generator_for_ui(), get_assembled_message

# --- Streamlit ì•± ---
st.title("ğŸ’¬ ì±—ë´‡ (Gemini + LangChain Tools)")

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage(content="ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë•ëŠ” AI ë´‡ì´ë‹¤."), 
        AIMessage(content="How can I help you?")
    ]

# 5. ë©”ì‹œì§€ ì¶œë ¥ (SyntaxError ìˆ˜ì •)
for msg in st.session_state.messages:
    if isinstance(msg, SystemMessage): pass
    elif isinstance(msg, AIMessage): st.chat_message("assistant").write(msg.content)
    elif isinstance(msg, HumanMessage): st.chat_message("user").write(msg.content)
    elif isinstance(msg, ToolMessage):
        # f-stringì„ í•œ ì¤„ë¡œ ìˆ˜ì •
        st.chat_message("tool").write(f"Tool (get_current_time): {msg.content}")

# --- 6. (ë¡œì§ ì „ë©´ ìˆ˜ì •) ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ---
if prompt := st.chat_input():
    st.chat_message("user").write(prompt)
    st.session_state.messages.append(HumanMessage(content=prompt))

    # 1. ì²« ë²ˆì§¸ ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)
    ui_container = st.chat_message("assistant")
    stream_gen, get_message_func = stream_and_assemble_response(st.session_state.messages)
    
    # UIì— ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (write_streamì˜ ë°˜í™˜ ê°’ì€ ì‚¬ìš© ì•ˆ í•¨!)
    ui_container.write_stream(stream_gen)
    
    # ìŠ¤íŠ¸ë¦¬ë°ì´ ëë‚œ í›„, ì¡°ë¦½ëœ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
    gathered_message = get_message_func()
    st.session_state.messages.append(gathered_message) # Pydantic ì˜¤ë¥˜ í•´ê²°!

    # 2. ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ”ì§€ í™•ì¸
    if gathered_message.tool_calls:
        # 3. ë„êµ¬ ì‹¤í–‰
        for tool_call in gathered_message.tool_calls:
            selected_tool = tool_dict[tool_call['name']]
            # Pydantic/ì¼ë°˜ í•¨ìˆ˜ í˜¸í™˜ì„ ìœ„í•´ 'args' ì‚¬ìš©
            tool_msg_content = selected_tool.invoke(tool_call['args'])
            
            tool_message = ToolMessage(content=str(tool_msg_content), tool_call_id=tool_call['id'])
            st.session_state.messages.append(tool_message)
            # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë„ UIì— í‘œì‹œ
            st.chat_message("tool").write(f"Tool ({tool_call['name']}): {tool_msg_content}")
        
        # 4. ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ *ìµœì¢…* ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)
        final_ui_container = st.chat_message("assistant")
        final_stream_gen, get_final_message_func = stream_and_assemble_response(st.session_state.messages)
        
        final_ui_container.write_stream(final_stream_gen)
        
        # ìµœì¢… ë©”ì‹œì§€ ì €ì¥
        final_gathered_message = get_final_message_func()
        st.session_state.messages.append(final_gathered_message)