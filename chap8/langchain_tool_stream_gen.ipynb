{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: langchain_google_genai in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (1.0.0)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.37)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Using cached ormsgpack-1.11.0-cp313-cp313-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.7.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_google_genai) (0.8.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (2.26.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (2.41.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.75.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (5.29.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.7.0->langchain_google_genai) (0.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\ziclp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.1)\n",
      "Downloading langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Using cached langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Using cached ormsgpack-1.11.0-cp313-cp313-win_amd64.whl (112 kB)\n",
      "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "\n",
      "   ------ --------------------------------- 1/6 [langgraph-sdk]\n",
      "   ------ --------------------------------- 1/6 [langgraph-sdk]\n",
      "   ------------- -------------------------- 2/6 [langgraph-checkpoint]\n",
      "   ------------- -------------------------- 2/6 [langgraph-checkpoint]\n",
      "   ------------- -------------------------- 2/6 [langgraph-checkpoint]\n",
      "   -------------------- ------------------- 3/6 [langgraph-prebuilt]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   -------------------------- ------------- 4/6 [langgraph]\n",
      "   --------------------------------- ------ 5/6 [langchain]\n",
      "   --------------------------------- ------ 5/6 [langchain]\n",
      "   --------------------------------- ------ 5/6 [langchain]\n",
      "   --------------------------------- ------ 5/6 [langchain]\n",
      "   --------------------------------- ------ 5/6 [langchain]\n",
      "   --------------------------------- ------ 5/6 [langchain]\n",
      "   ---------------------------------------- 6/6 [langchain]\n",
      "\n",
      "Successfully installed langchain-1.0.2 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 ormsgpack-1.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gemini API ì‘ë‹µ ---\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ì¸ê³µì§€ëŠ¥ì´ë¼ íŠ¹ë³„íˆ 'ì˜ ì§€ë‚¸ë‹¤'ê³  ë§í•˜ê¸°ëŠ” ì–´ë µì§€ë§Œ, í•­ìƒ ë¬¸ì œì—†ì´ ì˜ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì§ˆë¬¸í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ìš©ìë‹˜ì€ ì˜ ì§€ë‚´ì…¨ë‚˜ìš”? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ---\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"'GOOGLE_API_KEY' í™˜ê²½ ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "response = llm.invoke([HumanMessage(\"ì˜ ì§€ëƒˆì–´?\")])\n",
    "print(\"--- Gemini API ì‘ë‹µ ---\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gemini API ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ---\n",
      "ë„¤, ë•ë¶„ì— ì˜ ì§€ëƒˆìŠµë‹ˆë‹¤. í•œêµ­ ì‚¬íšŒì˜ ë¬¸ì œì ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ ë‹¬ë¼ê³  í•˜ì‹œë‹ˆ, ëª‡ ê°€ì§€ ì£¼ìš” ì´ìŠˆë“¤ì„ ì •ë¦¬í•´ì„œ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. í•œêµ­ì€ ì§§ì€ ì‹œê°„ ì•ˆì— ëˆˆë¶€ì‹  ê²½ì œ ì„±ì¥ì„ ì´ë£¨ì—ˆì§€ë§Œ|, ê·¸ ê³¼ì •ì—ì„œ ì—¬ëŸ¬ ì‚¬íšŒì  ë¬¸ì œë“¤ì´ í•¨ê»˜ ë‚˜íƒ€ë‚¬ê³ , í˜„ì¬ë„ ë³µí•©ì ìœ¼ë¡œ ì–½í˜€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì£¼ìš” ë¬¸ì œì ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1.  **ì €ì¶œì‚° ë° ê³ ë ¹í™” ë¬¸ì œ:**\n",
      "    *|   **ì„¸ê³„ ìµœì € ì¶œì‚°ìœ¨:** í•œêµ­ì€ ì„¸ê³„ì—ì„œ ê°€ì¥ ë‚®ì€ í•©ê³„ì¶œì‚°ìœ¨(2023ë…„ ê¸°ì¤€ 0.72ëª…)ì„ ê¸°ë¡í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë¯¸ë˜ ì‚¬íšŒì˜ ìƒì‚°ì„± ì €í•˜,| êµ­ë°©ë ¥ ì•½í™”, ë‚´ìˆ˜ ì‹œì¥ ì¶•ì†Œ ë“± ì‹¬ê°í•œ ìœ„í˜‘ìœ¼ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.\n",
      "    *   **ê¸‰ê²©í•œ ê³ ë ¹í™”:** ì¶œì‚°ìœ¨ ê°ì†Œì™€ ì˜í•™ ê¸°ìˆ  ë°œë‹¬ë¡œ ì¸í•œ ê¸°ëŒ€ ìˆ˜|ëª… ì¦ê°€ë¡œ ì‚¬íšŒ ì „ì²´ê°€ ë¹ ë¥´ê²Œ ê³ ë ¹í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì—°ê¸ˆ ê³ ê°ˆ, ì˜ë£Œë¹„ ë¶€ë‹´ ì¦ê°€, ë…¸ë™ë ¥ ë¶€ì¡± ë“±ì˜ ë¬¸ì œë¥¼ ì•¼ê¸°í•©ë‹ˆë‹¤.\n",
      "\n",
      "2.  **ê²½ì œ ì–‘ê·¹í™” ë° ë¶ˆí‰ë“± ì‹¬í™”:**\n",
      "    |*   **ì†Œë“ ë¶ˆê· í˜•:** ê²½ì œ ì„±ì¥ì—ë„ ë¶ˆêµ¬í•˜ê³  ì†Œë“ ìƒìœ„ì¸µê³¼ í•˜ìœ„ì¸µ ê°„ì˜ ê²©ì°¨ê°€ ë²Œì–´ì§€ê³  ìˆìœ¼ë©°, ì´ëŠ” ì‚¬íšŒì  ë°•íƒˆê°ê³¼ ë¶ˆë§Œì„ í‚¤ìš°ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "    *   |**ë¶€ë™ì‚° ë¬¸ì œ:** íŠ¹íˆ ìˆ˜ë„ê¶Œì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ì£¼íƒ ê°€ê²© í­ë“±ì€ ì Šì€ ì„¸ëŒ€ì˜ ì£¼ê±° ë¶ˆì•ˆì„ ê°€ì¤‘ì‹œí‚¤ê³ , ê³„ì¸µ ì´ë™ì˜ ì‚¬ë‹¤ë¦¬ë¥¼ ë§‰ëŠ” ìš”ì¸ìœ¼ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.\n",
      "    *   **ëŒ€|ê¸°ì—…-ì¤‘ì†Œê¸°ì—… ê²©ì°¨:** ëŒ€ê¸°ì—…ê³¼ ì¤‘ì†Œê¸°ì—… ê°„ì˜ ì„ê¸ˆ, ë³µì§€, ê³ ìš© ì•ˆì •ì„± ë“±ì˜ ê²©ì°¨ê°€ ì»¤ì„œ, ì²­ë…„ë“¤ì´ ì¢‹ì€ ì¼ìë¦¬ë¥¼ ì°¾ê¸° ì–´ë ¤ìš´ í˜„ì‹¤ì…ë‹ˆë‹¤.\n",
      "\n",
      "3.|  **ê³¼ë„í•œ ê²½ìŸ ë° ì •ì‹  ê±´ê°• ë¬¸ì œ:**\n",
      "    *   **í•™ë ¥/ì·¨ì—… ê²½ìŸ:** ìœ ì•„ê¸°ë¶€í„° ì‹œì‘ë˜ëŠ” ê·¹ì‹¬í•œ í•™ë ¥ ê²½ìŸì€ ì‚¬êµìœ¡ë¹„ ë¶€ë‹´ì„ ê°€ì¤‘ì‹œí‚¤ê³ , ì²­ë…„ë“¤ì€| ì·¨ì—…ì„ ìœ„í•´ ëì—†ëŠ” ìŠ¤í™ ìŒ“ê¸°ì— ë‚´ëª°ë¦½ë‹ˆë‹¤.\n",
      "    *   **ë†’ì€ ìŠ¤íŠ¸ë ˆìŠ¤ì™€ ìì‚´ë¥ :** ì´ëŸ¬í•œ ê³¼ë„í•œ ê²½ìŸê³¼ ì‚¬íšŒì  ì••ë°•ì€ ë†’ì€ ìŠ¤íŠ¸ë ˆìŠ¤ì™€ ìš°ìš¸ì¦ìœ¼ë¡œ ì´ì–´ì§€ë©°,| OECD êµ­ê°€ ì¤‘ ê°€ì¥ ë†’ì€ ìì‚´ë¥ ì„ ê¸°ë¡í•˜ëŠ” ì£¼ìš” ì›ì¸ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
      "    *   **ì§ì¥ ë¬¸í™”:** ê¸´ ê·¼ë¬´ ì‹œê°„, ê²½ì§ëœ ìƒí•˜ ê´€ê³„, íšŒì‹ ë¬¸í™” ë“±ì€ ì§ì¥ì¸ì˜ ë²ˆì•„ì›ƒê³¼| ì›Œë¼ë°¸(Work-Life Balance) ë¶ˆê· í˜•ì„ ì‹¬í™”ì‹œí‚µë‹ˆë‹¤.\n",
      "\n",
      "4.  **ì  ë” ê°ˆë“± ë° ì„±ì°¨ë³„ ë¬¸ì œ:**\n",
      "    *   **ì„±ì°¨ë³„ ì¸ì‹:** ì—¬ì „íˆ ë§ì€ ë¶„ì•¼|ì—ì„œ ì„±ì°¨ë³„ì  ì¸ì‹ì´ ë‚¨ì•„ìˆìœ¼ë©°, íŠ¹íˆ ì§ì¥ ë‚´ ìœ ë¦¬ì²œì¥ì´ë‚˜ ì„ê¸ˆ ê²©ì°¨ ë¬¸ì œ ë“±ì´ ì§€ì ë©ë‹ˆë‹¤.\n",
      "    *   **ì  ë” ê°ˆë“± ì‹¬í™”:** ìµœê·¼ ëª‡ ë…„ê°„ ì˜¨ë¼ì¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‚¨|ì„±ê³¼ ì—¬ì„± ê°„ì˜ ê°ˆë“±ì´ ì‹¬í™”ë˜ê³  ìˆìœ¼ë©°, ì´ëŠ” ì‚¬íšŒ í†µí•©ì„ ì €í•´í•˜ê³  ì‚¬íšŒì  ë¹„ìš©ì„ ë°œìƒì‹œí‚¤ëŠ” ìš”ì¸ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5.  **ë””ì§€í„¸ ì‚¬íšŒì˜ ì—­ê¸°ëŠ¥:**\n",
      "    *   **ë””|ì§€í„¸ ì¤‘ë…:** ìŠ¤ë§ˆíŠ¸í°ê³¼ ì¸í„°ë„· ì‚¬ìš©ì´ ë³´í¸í™”ë˜ë©´ì„œ ë””ì§€í„¸ ê¸°ê¸° ì¤‘ë… ë¬¸ì œê°€ ì‹¬ê°í•˜ë©°, íŠ¹íˆ ì²­ì†Œë…„ë“¤ì—ê²Œ ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "    *   **ê°€ì§œ ë‰´ìŠ¤ ë° ì‚¬ì´ë²„| í­ë ¥:** ì˜¨ë¼ì¸ì„ í†µí•œ ê°€ì§œ ë‰´ìŠ¤ í™•ì‚°ì€ ì‚¬íšŒì  í˜¼ë€ì„ ì•¼ê¸°í•˜ê³ , ì‚¬ì´ë²„ í­ë ¥ì€ ê°œì¸ì—ê²Œ í° ìƒì²˜ë¥¼ ì¤ë‹ˆë‹¤.\n",
      "\n",
      "6.  **ì§€ì—­ ì†Œë©¸ ë° ë¶ˆê· í˜• ë°œì „|:**\n",
      "    *   **ìˆ˜ë„ê¶Œ ì§‘ì¤‘:** ì¸êµ¬, ê²½ì œë ¥, ë¬¸í™” ì‹œì„¤ ë“±ì´ ìˆ˜ë„ê¶Œì— ê³¼ë„í•˜ê²Œ ì§‘ì¤‘ë˜ë©´ì„œ ì§€ë°©ì€ ì¸êµ¬ ê°ì†Œì™€ ê²½ì œ ì¹¨ì²´ë¡œ ì†Œë©¸ ìœ„ê¸°ì— ì§ë©´í•˜ê³  ìˆìŠµë‹ˆë‹¤.|\n",
      "    *   **ì§€ë°© ì˜ë£Œ/êµìœ¡ ì¸í”„ë¼ ë¶€ì¡±:** ìˆ˜ë„ê¶Œ ì§‘ì¤‘ í˜„ìƒì€ ì§€ë°©ì˜ ì˜ë£Œ, êµìœ¡, ë¬¸í™” ë“± í•„ìˆ˜ ì¸í”„ë¼ ë¶€ì¡±ìœ¼ë¡œ ì´ì–´ì ¸ ì‚¶ì˜ ì§ˆ ê²©ì°¨ë¥¼ ì‹¬í™”ì‹œí‚µë‹ˆë‹¤.|\n",
      "\n",
      "ì´ ì™¸ì—ë„ ì •ì¹˜ì  ì–‘ê·¹í™”, ê¸°í›„ ë³€í™” ëŒ€ì‘ ë¯¸í¡, ì‚¬íšŒ ì•ˆì „ë§ ë¶€ì¡± ë“± ë‹¤ì–‘í•œ ë¬¸ì œë“¤ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë“¤ì€ ì„œë¡œ ë³µì¡í•˜ê²Œ ì–½í˜€ ìˆì–´ ì–´ëŠ í•˜ë‚˜ë§Œ í•´ê²°í•´ì„œëŠ” ì „ì²´ì ì¸ ê°œì„ |ì„ ì´ë£¨ê¸° ì–´ë µìŠµë‹ˆë‹¤. í•œêµ­ ì‚¬íšŒëŠ” ì´ëŸ¬í•œ ë¬¸ì œë“¤ì„ ì¸ì‹í•˜ê³  í•´ê²°í•˜ê¸° ìœ„í•´ ë§ì€ ë…¸ë ¥ì„ ê¸°ìš¸ì´ê³  ìˆìœ¼ë©°, ì§€ì†ì ì¸ ì‚¬íšŒì  ë…¼ì˜ì™€ ì •ì±…ì  ì ‘ê·¼ì´ í•„ìš”í•œ ì‹œì ì…ë‹ˆë‹¤.||\n",
      "--- ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ ---\n"
     ]
    }
   ],
   "source": [
    "if 'GOOGLE_API_KEY' in os.environ:\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "    print(\"--- Gemini API ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ---\")\n",
    "    prompt = [HumanMessage(\"ì˜ ì§€ëƒˆì–´? í•œêµ­ ì‚¬íšŒì˜ ë¬¸ì œì ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ì¤˜.\")]\n",
    "    \n",
    "    # ğŸ’¡ flush=True ì¶”ê°€\n",
    "    for chunk in llm.stream(prompt):\n",
    "        print(chunk.content, end='|', flush=True)\n",
    "    \n",
    "    print(\"\\n--- ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "@tool # @tool ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í•¨ìˆ˜ë¥¼ ë„êµ¬ë¡œ ë“±ë¡\n",
    "def get_current_time(timezone: str, location: str) -> str:\n",
    "    \"\"\" í˜„ì¬ ì‹œê°ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "\n",
    "    Args:\n",
    "        timezone (str): íƒ€ì„ì¡´ (ì˜ˆ: 'Asia/Seoul') ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íƒ€ì„ì¡´ì´ì–´ì•¼ í•¨\n",
    "        location (str): ì§€ì—­ëª…. íƒ€ì„ì¡´ì´ ëª¨ë“  ì§€ëª…ì— ëŒ€ì‘ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì´í›„ llm ë‹µë³€ ìƒì„±ì— ì‚¬ìš©ë¨\n",
    "    \"\"\"\n",
    "    tz = pytz.timezone(timezone)\n",
    "    now = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    location_and_local_time = f'{timezone} ({location}) í˜„ì¬ì‹œê° {now} ' # íƒ€ì„ì¡´, ì§€ì—­ëª…, í˜„ì¬ì‹œê°ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜\n",
    "    print(location_and_local_time)\n",
    "    return location_and_local_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„êµ¬ë¥¼ tools ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ê³ , tool_dictì—ë„ ì¶”ê°€\n",
    "tools = [get_current_time,]\n",
    "tool_dict = {\"get_current_time\": get_current_time,}\n",
    "\n",
    "# ë„êµ¬ë¥¼ ëª¨ë¸ì— ë°”ì¸ë”©: ëª¨ë¸ì— ë„êµ¬ë¥¼ ë°”ì¸ë”©í•˜ë©´, ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ llm ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆìŒ\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ toolsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_vz1sES73m9UcQQSxLe3AeJSV', 'function': {'arguments': '{\"timezone\":\"Asia/Seoul\",\"location\":\"ë¶€ì‚°\"}', 'name': 'get_current_time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 135, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0ae931d8-10dd-442e-86c9-d4e535f6e902-0', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': 'ë¶€ì‚°'}, 'id': 'call_vz1sES73m9UcQQSxLe3AeJSV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 135, 'output_tokens': 24, 'total_tokens': 159, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# (4) ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ tools ì‚¬ìš©í•˜ì—¬ llm ë‹µë³€ ìƒì„±\n",
    "messages = [\n",
    "    SystemMessage(\"ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ toolsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\"),\n",
    "    HumanMessage(\"ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?\"),\n",
    "]\n",
    "\n",
    "# (5) llm_with_toolsë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ llm ë‹µë³€ ìƒì„±\n",
    "response = llm_with_tools.invoke(messages)\n",
    "messages.append(response)\n",
    "\n",
    "# (6) ìƒì„±ëœ llm ë‹µë³€ ì¶œë ¥\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timezone': 'Asia/Seoul', 'location': 'ë¶€ì‚°'}\n",
      "Asia/Seoul (ë¶€ì‚°) í˜„ì¬ì‹œê° 2025-02-18 01:08:09 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ toolsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_vz1sES73m9UcQQSxLe3AeJSV', 'function': {'arguments': '{\"timezone\":\"Asia/Seoul\",\"location\":\"ë¶€ì‚°\"}', 'name': 'get_current_time'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 135, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0ae931d8-10dd-442e-86c9-d4e535f6e902-0', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': 'ë¶€ì‚°'}, 'id': 'call_vz1sES73m9UcQQSxLe3AeJSV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 135, 'output_tokens': 24, 'total_tokens': 159, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Asia/Seoul (ë¶€ì‚°) í˜„ì¬ì‹œê° 2025-02-18 01:08:09 ', name='get_current_time', tool_call_id='call_vz1sES73m9UcQQSxLe3AeJSV')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = tool_dict[tool_call[\"name\"]] # (7) tool_dictë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ í•¨ìˆ˜ë¥¼ ì„ íƒ\n",
    "    print(tool_call[\"args\"]) # (8) ë„êµ¬ í˜¸ì¶œ ì‹œ ì „ë‹¬ëœ ì¸ì ì¶œë ¥\n",
    "    tool_msg = selected_tool.invoke(tool_call) # (9) ë„êµ¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ë¶€ì‚°ì€ í˜„ì¬ 2025ë…„ 2ì›” 18ì¼ 01ì‹œ 08ë¶„ 09ì´ˆì…ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 192, 'total_tokens': 219, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-b6423f78-b1ce-4016-bf64-ff2f2d3646b0-0', usage_metadata={'input_tokens': 192, 'output_tokens': 27, 'total_tokens': 219, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class StockHistoryInput(BaseModel):\n",
    "    ticker: str = Field(..., title=\"ì£¼ì‹ ì½”ë“œ\", description=\"ì£¼ì‹ ì½”ë“œ (ì˜ˆ: AAPL)\")\n",
    "    period: str = Field(..., title=\"ê¸°ê°„\", description=\"ì£¼ì‹ ë°ì´í„° ì¡°íšŒ ê¸°ê°„ (ì˜ˆ: 1d, 1mo, 1y)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "@tool\n",
    "def get_yf_stock_history(stock_history_input: StockHistoryInput) -> str:\n",
    "    \"\"\" ì£¼ì‹ ì¢…ëª©ì˜ ê°€ê²© ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    stock = yf.Ticker(stock_history_input.ticker)\n",
    "    history = stock.history(period=stock_history_input.period)\n",
    "    history_md = history.to_markdown() \n",
    "\n",
    "    return history_md\n",
    "\n",
    "tools = [get_current_time, get_yf_stock_history]\n",
    "tool_dict = {\"get_current_time\": get_current_time, \"get_yf_stock_history\": get_yf_stock_history}\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_3hvAMT8EY9JeBvNWaKJ256A6', 'function': {'arguments': '{\"stock_history_input\":{\"ticker\":\"TSLA\",\"period\":\"1mo\"}}', 'name': 'get_yf_stock_history'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 283, 'total_tokens': 311, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-c531f56b-a2ed-42eb-be54-4600ef8824c7-0' tool_calls=[{'name': 'get_yf_stock_history', 'args': {'stock_history_input': {'ticker': 'TSLA', 'period': '1mo'}}, 'id': 'call_3hvAMT8EY9JeBvNWaKJ256A6', 'type': 'tool_call'}] usage_metadata={'input_tokens': 283, 'output_tokens': 28, 'total_tokens': 311, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "messages.append(HumanMessage(\"í…ŒìŠ¬ë¼ëŠ” í•œë‹¬ ì „ì— ë¹„í•´ ì£¼ê°€ê°€ ì˜¬ëë‚˜ ë‚´ë ¸ë‚˜?\"))\n",
    "\n",
    "response = llm_with_tools.invoke(messages)\n",
    "print(response)\n",
    "messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stock_history_input': {'ticker': 'TSLA', 'period': '1mo'}}\n",
      "content='| Date                      |   Open |   High |    Low |   Close |      Volume |   Dividends |   Stock Splits |\\n|:--------------------------|-------:|-------:|-------:|--------:|------------:|------------:|---------------:|\\n| 2025-01-15 00:00:00-05:00 | 409.9  | 429.8  | 405.66 |  428.22 | 8.13755e+07 |           0 |              0 |\\n| 2025-01-16 00:00:00-05:00 | 423.49 | 424    | 409.13 |  413.82 | 6.83352e+07 |           0 |              0 |\\n| 2025-01-17 00:00:00-05:00 | 421.5  | 439.74 | 419.75 |  426.5  | 9.49914e+07 |           0 |              0 |\\n| 2025-01-21 00:00:00-05:00 | 432.64 | 433.2  | 406.31 |  424.07 | 8.73209e+07 |           0 |              0 |\\n| 2025-01-22 00:00:00-05:00 | 416.81 | 428    | 414.59 |  415.11 | 6.09633e+07 |           0 |              0 |\\n| 2025-01-23 00:00:00-05:00 | 416.06 | 420.73 | 408.95 |  412.38 | 5.06906e+07 |           0 |              0 |\\n| 2025-01-24 00:00:00-05:00 | 414.45 | 418.88 | 405.78 |  406.58 | 5.64271e+07 |           0 |              0 |\\n| 2025-01-27 00:00:00-05:00 | 394.8  | 406.69 | 389    |  397.15 | 5.81255e+07 |           0 |              0 |\\n| 2025-01-28 00:00:00-05:00 | 396.91 | 400.59 | 386.5  |  398.09 | 4.89107e+07 |           0 |              0 |\\n| 2025-01-29 00:00:00-05:00 | 395.21 | 398.59 | 384.48 |  389.1  | 6.80336e+07 |           0 |              0 |\\n| 2025-01-30 00:00:00-05:00 | 410.78 | 412.5  | 384.41 |  400.28 | 9.80929e+07 |           0 |              0 |\\n| 2025-01-31 00:00:00-05:00 | 401.53 | 419.99 | 401.34 |  404.6  | 8.35682e+07 |           0 |              0 |\\n| 2025-02-03 00:00:00-05:00 | 386.68 | 389.17 | 374.36 |  383.68 | 9.37321e+07 |           0 |              0 |\\n| 2025-02-04 00:00:00-05:00 | 382.63 | 394    | 381.4  |  392.21 | 5.70722e+07 |           0 |              0 |\\n| 2025-02-05 00:00:00-05:00 | 387.51 | 388.39 | 375.53 |  378.17 | 5.72233e+07 |           0 |              0 |\\n| 2025-02-06 00:00:00-05:00 | 373.03 | 375.4  | 363.18 |  374.32 | 7.79182e+07 |           0 |              0 |\\n| 2025-02-07 00:00:00-05:00 | 370.19 | 380.55 | 360.34 |  361.62 | 7.02983e+07 |           0 |              0 |\\n| 2025-02-10 00:00:00-05:00 | 356.21 | 362.7  | 350.51 |  350.73 | 7.75149e+07 |           0 |              0 |\\n| 2025-02-11 00:00:00-05:00 | 345.8  | 349.37 | 325.1  |  328.5  | 1.18543e+08 |           0 |              0 |\\n| 2025-02-12 00:00:00-05:00 | 329.94 | 346.4  | 329.12 |  336.51 | 1.05383e+08 |           0 |              0 |\\n| 2025-02-13 00:00:00-05:00 | 345    | 358.69 | 342.85 |  355.94 | 8.94415e+07 |           0 |              0 |\\n| 2025-02-14 00:00:00-05:00 | 360.62 | 362    | 347.5  |  355.84 | 6.80547e+07 |           0 |              0 |' name='get_yf_stock_history' tool_call_id='call_3hvAMT8EY9JeBvNWaKJ256A6'\n"
     ]
    }
   ],
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = tool_dict[tool_call[\"name\"]]\n",
    "    print(tool_call[\"args\"])\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "    print(tool_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='í•œ ë‹¬ ì „, ì¦‰ 2025ë…„ 1ì›” 15ì¼ì— í…ŒìŠ¬ë¼(TSLA)ì˜ ì¢…ê°€ëŠ” 428.22ë‹¬ëŸ¬ì˜€ê³ , ìµœê·¼ì¸ 2025ë…„ 2ì›” 14ì¼ì—ëŠ” ì¢…ê°€ê°€ 355.84ë‹¬ëŸ¬ì…ë‹ˆë‹¤. \\n\\në”°ë¼ì„œ í…ŒìŠ¬ë¼ì˜ ì£¼ê°€ëŠ” í•œ ë‹¬ ì „ë³´ë‹¤ ë‚´ë ¸ìŠµë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 1642, 'total_tokens': 1720, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-c9f5f3e1-4099-4e51-8355-fb5d9642c51a-0', usage_metadata={'input_tokens': 1642, 'output_tokens': 78, 'total_tokens': 1720, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08-4 ìŠ¤íŠ¸ë¦¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|ì•ˆ|ë…•í•˜ì„¸ìš”|!| í•œêµ­| ì‚¬íšŒ|ì—ëŠ”| ì—¬ëŸ¬| ê°€ì§€| ë¬¸ì œ|ì |ì´| ìˆì§€ë§Œ|,| ëª‡| ê°€ì§€| ì£¼ìš”|í•œ| ì´|ìŠˆ|ë¥¼| ì´ì•¼ê¸°|í•´|ë³´|ê² ìŠµë‹ˆë‹¤|.\n",
      "\n",
      "|1|.| **|ê³ |ìš©| ë¬¸ì œ|**|:| ì²­|ë…„| ì‹¤|ì—…|ë¥ |ì´| ë†’|ê³ |,| ë¹„|ì •|ê·œ|ì§| ê³ |ìš©|ì´| ì¦ê°€|í•˜ëŠ”| ì¶”|ì„¸|ì…ë‹ˆë‹¤|.| ë§ì€| ì Š|ì€|ì´|ë“¤ì´| ì•ˆì •|ì ì¸| ì¼|ì|ë¦¬ë¥¼| ì°¾|ê¸°| ì–´ë ¤|ì›Œ|í•˜ê³ |,| ê³ |ìš©|ì˜| ì§ˆ|ì´| ë‚®|ì•„|ì§€ëŠ”| ë¬¸ì œê°€| ìˆìŠµë‹ˆë‹¤|.\n",
      "\n",
      "|2|.| **|ì†Œ|ë“| ë¶ˆ|í‰|ë“±|**|:| ì†Œ|ë“| ë¶„|ë°°|ì˜| ë¶ˆ|ê· |í˜•|ì´| ì‹¬|í™”|ë˜ê³ | ìˆìœ¼ë©°|,| íŠ¹íˆ| ëŒ€|ê¸°ì—…|ê³¼| ì¤‘|ì†Œ|ê¸°ì—…| ê°„|ì˜| ê²©|ì°¨|ê°€| í¬ê²Œ| ë²Œ|ì–´|ì§€ê³ | ìˆìŠµë‹ˆë‹¤|.| ì´|ë¡œ| ì¸í•´| ì‚¬íšŒ|ì | ê³„|ì¸µ| ê°„|ì˜| ê°ˆ|ë“±|ì´| ì‹¬|í™”|ë | ìˆ˜| ìˆìŠµë‹ˆë‹¤|.\n",
      "\n",
      "|3|.| **|ì£¼|ê±°|ë¬¸|ì œ|**|:| ê¸‰|ê²©|í•œ| ì„œìš¸|ê³¼| ìˆ˜ë„|ê¶Œ|ì˜| ì§‘|ê°’| ìƒìŠ¹|ìœ¼ë¡œ| ì¸í•´| ë§ì€| ì‚¬ëŒë“¤ì´| ì£¼|ê±°| ë¬¸ì œ|ì—| ì‹œ|ë‹¬|ë¦¬ê³ | ìˆìŠµë‹ˆë‹¤|.| íŠ¹íˆ| ì²­|ë…„|ì¸µ|ê³¼| ì‚¬íšŒ|ì´ˆ|ë…„|ìƒ|ë“¤ì€| ë†’ì€| ì§‘|ê°’|ìœ¼ë¡œ| ì¸í•´| ì£¼|ê±°| ì•ˆì •|ì„±ì„| í™•ë³´|í•˜ê¸°| í˜|ë“¤|ì–´|í•˜ê³ | ìˆìŠµë‹ˆë‹¤|.\n",
      "\n",
      "|4|.| **|ì •|ì‹ | ê±´ê°•| ë¬¸ì œ|**|:| ê³¼|ë„|í•œ| ê²½ìŸ|ê³¼| ìŠ¤íŠ¸|ë ˆìŠ¤|ëŠ”| ë§ì€| ì‚¬ëŒ|ë“¤ì—ê²Œ| ì •ì‹ |ì | ë¶€ë‹´|ì„| ì£¼|ë©°|,| ìš°|ìš¸|ì¦|ì´ë‚˜| ë¶ˆ|ì•ˆ|ì¥|ì• | ê°™ì€| ë¬¸ì œê°€| ì¦ê°€|í•˜ê³ | ìˆìŠµë‹ˆë‹¤|.| ì´ëŸ¬í•œ| ë¬¸ì œ|ëŠ”| ì‚¬íšŒ|ì ìœ¼ë¡œ|ë„| í°| ì˜í–¥ì„| ë¯¸|ì¹˜|ê³ | ìˆìœ¼|ë‚˜|,| ì—¬|ì „íˆ| stig|mat|ization|ì´| ì¡´ì¬|í•©ë‹ˆë‹¤|.\n",
      "\n",
      "|5|.| **|ì„±| í‰|ë“±| ë¬¸ì œ|**|:| ì„±|ë³„|ì—| ë”°ë¥¸| ì„|ê¸ˆ| ì°¨|ë³„|ì´ë‚˜| ê³ |ìš©| ë¶ˆ|ê· |í˜•|,| ê°€|ì •| ë‚´| ì„±|í­|ë ¥| ë“±ì˜| ë¬¸ì œê°€| ì—¬|ì „íˆ| ì¡´ì¬|í•©ë‹ˆë‹¤|.| ì´ëŸ¬í•œ| ë¬¸ì œ|ë“¤ì€| ì‚¬íšŒ|ì | ì¸|ì‹| ê°œì„ |ê³¼| ë²•|ì | ì œ|ì¬|ê°€| í•„ìš”|í•©ë‹ˆë‹¤|.\n",
      "\n",
      "|6|.| **|ì¼|ê³¼| ì‚¶|ì˜| ê· |í˜•|**|:| í•œêµ­|ì€| ì—¬|ì „íˆ| ê¸´| ê·¼|ë¬´| ì‹œê°„|ê³¼| ê³¼|ë„|í•œ| ì—…ë¬´| ì••|ë°•|ì´| ìˆëŠ”| ì§|ì¥| ë¬¸í™”|ê°€| ë§Œ|ì—°|í•´| ìˆìŠµë‹ˆë‹¤|.| ì´ëŸ¬í•œ| ë¬¸í™”|ëŠ”| ê°œì¸|ì˜| ì‚¶|ì˜| ì§ˆ|ì„| ì €|í•˜ì‹œ|í‚¬| ìˆ˜| ìˆìŠµë‹ˆë‹¤|.\n",
      "\n",
      "|ì´| ì™¸|ì—ë„| ë‹¤ì–‘í•œ| ë¬¸ì œ|ë“¤ì´| ì¡´ì¬|í•˜ì§€ë§Œ|,| ì´ë¥¼| í•´ê²°|í•˜ê¸°| ìœ„í•œ| ì—¬ëŸ¬| ë…¸|ë ¥ì´| í•„ìš”|í•©ë‹ˆë‹¤|.| ì‚¬íšŒ|ì | ëŒ€|í™”|ì™€| ì •ì±…|ì | ê°œì„ |ì´| ì¤‘ìš”í•œ| ì‹œ|ì |ì—| ìˆìŠµë‹ˆë‹¤|.||"
     ]
    }
   ],
   "source": [
    "for c in llm.stream([HumanMessage(\"ì˜ ì§€ëƒˆì–´? í•œêµ­ ì‚¬íšŒì˜ ë¬¸ì œì ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ì¤˜.\")]):\n",
    "    print(c.content, end='|') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': ''}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/Se'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': ''}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': 'ë¶€'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': 'ë¶€ì‚°'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': 'ë¶€ì‚°'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n",
      "chunk type:  <class 'langchain_core.messages.ai.AIMessageChunk'>\n",
      "content:   tool_call_chunk [{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': 'ë¶€ì‚°'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ toolsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\"),\n",
    "    HumanMessage(\"ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?\"),\n",
    "]\n",
    "\n",
    "response = llm_with_tools.stream(messages)\n",
    "\n",
    "# íŒŒí¸í™”ëœ tool_call ì²­í¬ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° \n",
    "is_first = True\n",
    "for chunk in response:    \n",
    "    print(\"chunk type: \", type(chunk))\n",
    "    \n",
    "    if is_first:\n",
    "        is_first = False\n",
    "        gathered = chunk\n",
    "    else:\n",
    "        gathered += chunk\n",
    "    \n",
    "    print(\"content: \", gathered.content, \"tool_call_chunk\", gathered.tool_calls)\n",
    "\n",
    "messages.append(gathered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'function': {'arguments': '{\"timezone\":\"Asia/Seoul\",\"location\":\"ë¶€ì‚°\"}', 'name': 'get_current_time'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a'}, id='run-00266f14-0c23-4644-8306-7c9ae0e11156', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': 'ë¶€ì‚°'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'get_current_time', 'args': '{\"timezone\":\"Asia/Seoul\",\"location\":\"ë¶€ì‚°\"}', 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'index': 0, 'type': 'tool_call_chunk'}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gathered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timezone': 'Asia/Seoul', 'location': 'ë¶€ì‚°'}\n",
      "Asia/Seoul (ë¶€ì‚°) í˜„ì¬ì‹œê° 2025-02-18 01:09:36 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ toolsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ë¶€ì‚°ì€ ì§€ê¸ˆ ëª‡ì‹œì•¼?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'function': {'arguments': '{\"timezone\":\"Asia/Seoul\",\"location\":\"ë¶€ì‚°\"}', 'name': 'get_current_time'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a'}, id='run-00266f14-0c23-4644-8306-7c9ae0e11156', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': 'ë¶€ì‚°'}, 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'get_current_time', 'args': '{\"timezone\":\"Asia/Seoul\",\"location\":\"ë¶€ì‚°\"}', 'id': 'call_eScLJfZZaE0kTvF7GgupB0oq', 'index': 0, 'type': 'tool_call_chunk'}]),\n",
       " ToolMessage(content='Asia/Seoul (ë¶€ì‚°) í˜„ì¬ì‹œê° 2025-02-18 01:09:36 ', name='get_current_time', tool_call_id='call_eScLJfZZaE0kTvF7GgupB0oq')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in gathered.tool_calls:\n",
    "    selected_tool = tool_dict[tool_call[\"name\"]] # tool_dictë¥¼ ì‚¬ìš©í•˜ì—¬ ë„êµ¬ ì´ë¦„ìœ¼ë¡œ ë„êµ¬ í•¨ìˆ˜ë¥¼ ì„ íƒ\n",
    "    print(tool_call[\"args\"]) # ë„êµ¬ í˜¸ì¶œ ì‹œ ì „ë‹¬ëœ ì¸ì ì¶œë ¥\n",
    "    tool_msg = selected_tool.invoke(tool_call) # ë„êµ¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|ë¶€|ì‚°|ì€| ì§€ê¸ˆ| |202|5|ë…„| |2|ì›”| |18|ì¼| |01|ì‹œ| |09|ë¶„| |36|ì´ˆ|ì…ë‹ˆë‹¤|.||"
     ]
    }
   ],
   "source": [
    "for c in llm_with_tools.stream(messages):\n",
    "    print(c.content, end='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
